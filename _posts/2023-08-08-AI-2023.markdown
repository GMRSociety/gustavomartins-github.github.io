---
layout:     post
title:      "A história da AI"
subtitle:   " \"Kasparov X DeepBlue: o homem contra a máquina\""
date:       2023-08-08 22:30:00
author:     "Gustavo M.R."
header-img: "img/kasparov.jpg"
catalog: true
tags:
    - AI
---

> “O homem, ao mesmo tempo que sonha com todas as suas forças em inventar uma máquina mais forte do que ele mesmo, não pode admitir a possibilidadede não ser o mestre de suas criaturas. Tanto quanto Deus. Poderia Deus ter sonhado em criar o homem superior ao criador e em enfrentá-lo num combate decisivo? É o que, contudo, fazemos com nossas criaturas cibernéticas, às quais oferecemos a oportunidade de nos derrotar.” - <strong>Baudrillard 1997, p. 134</strong>

<p align = "justify">
    No dia 11 de maio de 1997, o maior jogador de xadrez da época e um entre os melhores da história, Garry Kasparov, perdeu uma série de 5 partidas para um computador especializado em xadrez denominado Deep Blue, uma inteligência artificial desenvolvida pela grandiosa IBM. Tal evento histórico atraiu muita atenção da mídia, principalmente pelo fato de, no ultimo jogo, Kasparov perder em apenas 19 lançes (algo muito dificil até mesmo entre os melhores enxadristas da época). Sendo assim, além de ser a primeira vez na história em que um computador venceu campeão mundial em uma partida de vários jogos, esse fato serviu como o início de uma nova era: a era da inteligência artificial.
</p>

## A influência da Mitologia e Ficção para a AI

<p align = "justify">
    Antes do surgimento da primeira inteligência artificial, a mitologia e a ficção científica teve um forte papel na difusão de ideias sobre sistemas inteligêntes capazes de imitar o ser humano. Em 400 A.C., de acordo com a mitologia grega, existia um ser construído em bronze que protegia a <strong>Ilha de Creta</strong>, atualmente localizada na Gŕecia. Já em 1818, a escritora britânica <strong>Mary Shelley</strong> publica sua obra <strong><i>Frankenstein or The Modern Prometheus</i></strong>, onde o cientista <strong>Victor Frankenstein</strong> cria um ser inteligente a partir de partes de seres humanos mortos. Mas foi somente em 1863 que <strong>Samuel Butler</strong>, por meio de seu artigo <strong><i>Darwin among the Machines</i></strong>, publicada no jornal The Press, sugeriu pela primeira vez que as máquinas, por evoluirem muito mais rápido e de maneira constante, superariam o ser humano com base na teoria da seleção natural darwiniana, podendo eventualmente torna-se a forma de vida dominante na terra.
</p>

<p align = "justify">
    Seguindo a cronológia dos fatos, em 1927, foi publicado a obra <strong>Metrópolis</strong>, um filme de drama/ficção científica cuja trama girava em torno de Maria, uma líder entre os trabalhadores, e um robô inteligente feito com uma aparência identica à ela, com a finalidade de desacreditá-la em meio aos trabalhadores. Em 1983, o filme <strong>War Games</strong> levantou algumas discussões interessantes: a inteligência artificial pode tomar decisões críticas como iniciar uma guerra? Como diferenciar a realidade do mundo virtual? Por tanto, tais eventos históricos citados foram de suma importância para o amadurecimento da inteligência artificial como ideia, para que em um futuro próximo viesse a ser realidade.
</p>

## O início da Inteligência Artificial (1943-1956)

<p align = "justify">
    Em meados de 1943, a obra <strong><i>A Logical Calculus of Ideas Immanent in Nervous Activity</i></strong> (Warren McCulloch e Walter Pitts) propôs ao mundo um modelo de neurônio artificial que representava um neurôneo como uma unidade lógica que recebe entradas binárias e produz uma saída, também binária, com base em regras lógicas (AND, OR, NOT, etc.), que ficou conhecido como <strong>neurônio de McCulloch-Pitts</strong>. Tal contribuição foi de suma importância para o desenvolvimento das primeiras redes neurais artificiais, onde o estado de um determinado neurôneo artificial varia conforme o estimulo de um número suficiente de outros neurôneos vizinhos (sinápse), evidenciando a possibilidade da humanidade em desenvolver sistemas computacionais que imitam aspectos da atividade cerebral.
</p>

<p align = "justify">
    Já em 1949, o psicólogo <strong>Donald Olding Hebb</strong> desenvolveu uma ideia, mais tarde conhecida como <strong>Aprendizagem Hebbiana</strong>, que explica como o cérebro pode aprender e formar memórias associativas com base na coocorrência de atividade entre neurônios. Para isso, tal ideia explica como os neurônios podem fortalecer suas conexões quando ativados simultaneamente. Segundo Hebb, quando um neurônio A é ativado e, em seguida, outro neurônio B é ativado imediatamente após, as sinapses (conexões) entre esses dois neurônios são fortalecidas. Isso ocorre porque a ativação simultânea sugere que a conexão entre eles é importante para a transmissão de informações. Por fim, tal ideia foi de suma importância para o desenvolvimento do que mais tarde ficou conhecido como <strong>Redes Neurais Artificiais</strong>
</p>

<p align = "justify">
    Seguindo a ordem cronológica da evolução da AI, em meados dos anos 50, <strong>Alan Turing</strong>, conhecido como o pai da computação, apresentou ao mundo conceitos como <strong>Teste de Turing</strong>, <strong><i>Machine Learning</i></strong>, <strong><i>Genetic Algorithms</i></strong> e <strong><i>Reinforcement Learning</i></strong>, além de defender a ideia de que seria mais fácil criar uma AI de nível humano desenvolvendo algoritmos de aprendizado para ensinar uma máquina ao invés de programar sua inteligência manualmente. Já em 1952, dois estudantes da famosa <i>Harvard University</i> criaram o sistema <strong>SNARC</strong> (<i>Stochastic Neural Analog Reinforcement Calculator</i>), que marcou a história como o primeiro computador de rede neural artificial. 
</p>

<p align = "justify">
    Por fim, em 1956, ocorreu um marco histórico na inteligência artificial: um workshop de verão denominado <strong>DSRPAI</strong> (<i>Dartmouth Summer Research Project on Artificial Intelligence</i>), organizado pelos proeminentes pesquisadores John McCarthy, Marvin Minsky, Nathaniel Rochester e Claude Shannon, o qual ocorreu na "Universidade de Dartmouth" (EUA). Esse evento foi considerado o primeiro cuja pauta principal era à AI e reuniu os principais pesquisadores de várias áreas do conhecimento para uma discussão aberta sobre inteligência artificial. A <strong>Imagem 1</strong> a seguir apresenta alguns dos principais membros presentes na DSPAI.
</p>

<figure>
    <img src="/img/DSRPAI_members.png"  width="624" height="532" align = "center">
    <figcaption align = "center"><strong>Imagem 1</strong>: os pais fundadores da AI <a href = "https://indiaai.gov.in/article/exploring-the-significance-of-the-dartmouth-workshop">(DSRPAI)</a></figcaption>
</figure>

## O entusiasmo inicial: grandes expectativas (1952-1969)

<p align = "justify">
    O período de 1952 à 1969 foi marcado por grandes feitos utilizando sistemas inteligentes, os quais geraram grandes expectativas. Alguns deles foram:
</p>

<ul align = "justify">
    <li>
        <strong>Arthur Samuel (1956)</strong>: ensinou um computador a jogar damas em um nível amador forte;
    </li>
    <li>
        <strong>Herbert Gelernter (1959)</strong>: contrução do "Provador do Teorema da Geometria" - sistema capaz de provar teoremas considerados complexos por alguns estudantes de Geometria;
    </li>
    <li>
        <strong>Frank Rosenblatt (1962)</strong>: desenvolvimento do "perceptron" - usado em redes neuaris;
    </li>
    <li>
        <strong>Bert Raphael (1969)</strong>:  blocks world (problemas de micro-mundo) - usado como caso de teste em pesquisas sobre sistemas de IA e lógica.
    </li>
</ul>

## Uma dose de realidade (1966-1973)

<p align = "justify">
    Apesar dos avanços mencionados no tópico anterior, alguns problemas vieram a tona. Durante o período de 1966 à 1973, análises foram feitas sobre os problemas resolvidos por meio de IA até então, o que levou a conclusão que tais problemas eram, de maneira geral, pouco complexos. Somado a isso, especificamente em 1969, Marvin Minsky e Seymour Papert, por meio do livro <strong><i>Perceptrons: An Introduction to Computational Geometry</i></strong>, demonstraram que os perceptrons simples, em sua forma mais básica de um único neurônio de camada única, eram limitados em termos de sua capacidade de representação mesmo que pudessem aprender sobre qualquer coisa as quais fossem capazes de representar. Por fim, a complexidade do <strong>problema da porta XOR</strong> (ou problema da disjunção exclusiva) desempenhou um papel significativo no que ficou conhecido como o <strong>inverno da AI</strong> (<i>AI winter</i>).
</p>

<p align = "justify">
    Diante do exposto, o inverno da AI refere a uma época de desaceleração na pesquisa e desenvolvimento em 
    inteligência artificial, que ocorreu principalmente durante as décadas de 1970 e 1980, onde muitas empresas faliram por não conseguir cumprir promessas extravagantes, como construir e manter <strong>sistemas especialistas</strong> para dominios complexos (esse assunto será abordado com mais detalhes mais à frente). Não obstante, alguns dos principais fatores para esse cenario baseiam-se nos métodos de raciocínio usados pelos sistemas da época, os quais falharam em face da incerteza, além da necessidade de avanços para permitir que os sistemas inteligentes pudessem aprender com a experiência. 
</p>

<p align = "justify">
    Somado a isso, para entender o problema da porta XOR, é necessario entender que essa porta produz uma saída verdadeira apenas quando exatamente
    uma de suas entradas é verdadeira. Isso faz com que essa porta não seja linearmente separável, fazendo com que o 
    perceptron não consiga resolvê-lo, levando o mundo à uma desilusão em relação à inteligência artificial e desacelerando
    as pesquisas sobre aprendizado de máquina e redes neurais.
</p>

## Sistemas Especialistas(1969-1986)

<p align = "justify">
    As décadas de 70 e 80 ficaram marcadas por pesquisas sobre inteligência artificial. Nesse período, estudava-se muito sobre o propósito geral da inteligência artificial, assim como o surgimento do que ficou conhecido como métodos fracos (AI fraca), isto é, sistemas de AI projetados para realizarem tarefas apenas dentro de um domínio específico, o que desencadeou em sistemas que não lidavam bem com contextos fora de sua área de atuação. Tal fato cuminou no desenvolvimento do que ficou conhecido como <strong>Sistemas Especialistas</strong>, que consistem em programas de AI capazes de imitar a expertise de um especialista humano em um campo particular do conhecimento, como medicina, engenharia, etc. Tais sistemas tinham como objetivo resolver problemas e responder perguntas dentro do seu domínio de atuação. Alguns exemplos de sistemas especialistas desse período foram: 
</p>

<ul align = "justify">
    <li>
        <strong>DENDRAL (1969)</strong>: sistema para inferir a estrutura molecular a partir de informações fornecidas por um espectrômetro de massa;
    </li>
    <li>
        <strong>MYCIN (1970)</strong>: sistema para diagnosticar infecções no sangue (baseado em 450 regras). Esse sistema ficou famoso pelo seu alto desempenho em relação à médicos da época.
    </li>
    <li>
        <strong>R1 (1982)</strong>: sistema de gerenciamento automatizado de empresa desenvolvido pela <i>Digital Equipment Corporation</i>. Foi considerado o primeiro sistema especialista comercial bem-sucedido e, em 1986, estava economizando cerca de U$ 40 milhões por ano para a empresa.
    </li>
</ul>

<p align = "justify">
    Diante do sucesso dos sistemas especialistas, centenas de empresas ao redor do mundo começaram a desenvolver novos sistemas especialistas, sistemas de visão, robôs, software e hardware especializado para esses fins. Isso fez com que a indústria de AI valorizasse de alguns milhões de dólares em 1980 para bilhões de dólares em 1988, fato este de suma importância para o desenvolvimento dessa indústria emergente. 
</p>

## O retorno das Redes Neurais (1986 em diante)

<!-- fiz 10 faltam 30 (1/4) Qual é a política de acesso ao meio em uma rede sem fio? Pesquisar em casa -->
<p align = "justify">
    Em meados da década de 80, houve uma evolução significativa sobre os algoritmos de <strong>aprendizado por retropropagação</strong> (desenvolvidos pela primeira vez em 1960). Também conhecido como <strong><i>backpropagation</i></strong>, esse modelo realiza uma passagem para trás para ajustar os parâmetros de um modelo de rede neural até que se ache o valor de peso ideal. Somado a isso, a industria da AI percebeu que os modelos conexionistas representavam melhor a realidade que os demais modelos disponíveis na época, principalmente devido à sua capacidade de aprender por meio de exemplos (dados). Isso tornava os sistemas baseados nesse modelo mais adaptáveis, podendo então ter melhores desempenho em relação à novos dados de treinamento.
</p>

<p align = "justify">
    Continuando, mais especificamente em 1998, David McAllester critica o isolacionismo que ocorreu no campo da inteligência artificial em seus estágios iniciais, argumentando que muitos pesquisadores  estavam focados em abordagens baseadas em símbolos (web semântica, frames, etc.) e acreditavam que essas abordagens tornariam obsoleta a teoria clássica de computação. Sendo assim, alegando que uma abordagem interdisciplinar e aberta era necessária para o progresso efetivo no campo da IA, David defendeu que a AI deveria ser integrada à outras disciplinas da ciência da computação, em especial o <strong>raciocínio probabilístico</strong> e <strong>aprendizado de máquina</strong>.
</p>

## Big Data (2001-presente)

<p align = "justify">
    (...)
</p>

## Deep learning (2011–presente)

<p align = "justify">
    (...)
</p>
